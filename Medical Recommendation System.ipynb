{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMivHUoWk0pxc6VnHja5saY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anarghapal/My-project/blob/main/Medical%20Recommendation%20System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dnAZdp6h_oO"
      },
      "outputs": [],
      "source": [
        "# Simple MedDoc - Medical Prognosis App (Colab Version)\n",
        "\n",
        "# Install required packages\n",
        "!pip install streamlit pandas numpy scikit-learn matplotlib seaborn pyngrok\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import os\n",
        "from google.colab import files\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to upload dataset\n",
        "def upload_dataset():\n",
        "    print(\"Please upload your Training2.csv file\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"Uploaded {filename}\")\n",
        "            df = pd.read_csv(filename)\n",
        "            return df\n",
        "    return None\n",
        "\n",
        "# Upload dataset\n",
        "df = upload_dataset()\n",
        "\n",
        "if df is None:\n",
        "    print(\"No file uploaded. Exiting.\")\n",
        "else:\n",
        "    # Clean dataset\n",
        "    # Remove empty and unnamed columns\n",
        "    cols_to_drop = [col for col in df.columns if col == '' or not col.strip() or df[col].nunique() == 0]\n",
        "    if cols_to_drop:\n",
        "        df = df.drop(columns=cols_to_drop)\n",
        "        print(f\"Removed {len(cols_to_drop)} empty/unnamed columns\")\n",
        "\n",
        "    # Split features and target\n",
        "    if 'prognosis' not in df.columns:\n",
        "        print(\"Error: Dataset must contain a 'prognosis' column\")\n",
        "    else:\n",
        "        X = df.drop('prognosis', axis=1)\n",
        "        y = df['prognosis']\n",
        "\n",
        "        # Encode target variable\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "        print(f\"Dataset shape: {df.shape}\")\n",
        "        print(f\"Number of symptoms: {X.shape[1]}\")\n",
        "        print(f\"Number of unique prognoses: {len(np.unique(y))}\")\n",
        "\n",
        "        # Split data for training\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Handle missing data\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_imputed = imputer.fit_transform(X_train)\n",
        "        X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "        # Train and compare models\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "            'SVM': SVC(probability=True, random_state=42),\n",
        "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "            'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "            'Naive Bayes': GaussianNB()\n",
        "        }\n",
        "\n",
        "        print(\"\\nTraining and comparing models...\")\n",
        "        model_results = []\n",
        "\n",
        "        for name, model in models.items():\n",
        "            print(f\"Training {name}...\")\n",
        "            model.fit(X_train_imputed, y_train)\n",
        "            y_pred = model.predict(X_test_imputed)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            model_results.append({'Model': name, 'Accuracy': accuracy})\n",
        "            print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Find best model\n",
        "        best_model_info = max(model_results, key=lambda x: x['Accuracy'])\n",
        "        best_model_name = best_model_info['Model']\n",
        "        best_model = models[best_model_name]\n",
        "\n",
        "        print(f\"\\nBest model: {best_model_name} with accuracy {best_model_info['Accuracy']:.4f}\")\n",
        "\n",
        "        # Save model and required files\n",
        "        with open('model.pkl', 'wb') as f:\n",
        "            pickle.dump(best_model, f)\n",
        "\n",
        "        with open('imputer.pkl', 'wb') as f:\n",
        "            pickle.dump(imputer, f)\n",
        "\n",
        "        with open('label_encoder.pkl', 'wb') as f:\n",
        "            pickle.dump(label_encoder, f)\n",
        "\n",
        "        with open('feature_list.pkl', 'wb') as f:\n",
        "            pickle.dump(list(X.columns), f)\n",
        "\n",
        "        print(\"Model and related files saved successfully!\")\n",
        "\n",
        "        # Create Streamlit app\n",
        "        print(\"\\nCreating Streamlit app...\")\n",
        "\n",
        "        # Write app code to file\n",
        "        with open('app.py', 'w') as f:\n",
        "            f.write('''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(\n",
        "    page_title=\"MedDoc - Symptom Checker\",\n",
        "    page_icon=\"ðŸ©º\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Add some CSS styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-title {\n",
        "        font-size: 32px;\n",
        "        font-weight: bold;\n",
        "        color: #2c3e50;\n",
        "        text-align: center;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    .result-box {\n",
        "        background-color: #e8f4f8;\n",
        "        padding: 20px;\n",
        "        border-radius: 5px;\n",
        "        margin-top: 20px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .warning {\n",
        "        color: #e74c3c;\n",
        "        font-style: italic;\n",
        "    }\n",
        "    .symptom-tag {\n",
        "        display: inline-block;\n",
        "        background-color: #e1f5fe;\n",
        "        padding: 2px 8px;\n",
        "        margin: 2px;\n",
        "        border-radius: 12px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state for prognosis log\n",
        "if 'prognosis_log' not in st.session_state:\n",
        "    st.session_state.prognosis_log = []\n",
        "\n",
        "# Load model and related files\n",
        "@st.cache_resource\n",
        "def load_files():\n",
        "    # Load model\n",
        "    with open('model.pkl', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # Load imputer\n",
        "    with open('imputer.pkl', 'rb') as f:\n",
        "        imputer = pickle.load(f)\n",
        "\n",
        "    # Load label encoder\n",
        "    with open('label_encoder.pkl', 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "\n",
        "    # Load feature list\n",
        "    with open('feature_list.pkl', 'rb') as f:\n",
        "        feature_list = pickle.load(f)\n",
        "\n",
        "    return model, imputer, label_encoder, feature_list\n",
        "\n",
        "# Main title\n",
        "st.markdown(\"<div class='main-title'>MedDoc: Medical Prognosis Prediction</div>\", unsafe_allow_html=True)\n",
        "st.markdown(\"Select your symptoms and get a potential prognosis\")\n",
        "\n",
        "# Load files\n",
        "model, imputer, label_encoder, feature_list = load_files()\n",
        "\n",
        "# Create tabs\n",
        "tab1, tab2 = st.tabs([\"Symptom Checker\", \"Prognosis Log\"])\n",
        "\n",
        "with tab1:\n",
        "    # Search box for symptoms\n",
        "    search = st.text_input(\"Search for symptoms:\")\n",
        "\n",
        "    # Filter symptoms based on search\n",
        "    filtered_symptoms = feature_list\n",
        "    if search:\n",
        "        filtered_symptoms = [s for s in feature_list if search.lower() in s.lower()]\n",
        "\n",
        "    # Group symptoms by category for better organization\n",
        "    pain_symptoms = [s for s in filtered_symptoms if 'pain' in s or 'ache' in s]\n",
        "    skin_symptoms = [s for s in filtered_symptoms if 'skin' in s or 'rash' in s]\n",
        "    digestive_symptoms = [s for s in filtered_symptoms if 'stomach' in s or 'vomit' in s or 'nausea' in s]\n",
        "    other_symptoms = [s for s in filtered_symptoms if s not in pain_symptoms + skin_symptoms + digestive_symptoms]\n",
        "\n",
        "    selected_symptoms = []\n",
        "\n",
        "    # Display symptoms by category using expanders\n",
        "    with st.expander(\"Pain Symptoms\", expanded=True):\n",
        "        if not pain_symptoms:\n",
        "            st.write(\"No matching symptoms found\")\n",
        "        else:\n",
        "            cols = st.columns(3)\n",
        "            for i, symptom in enumerate(sorted(pain_symptoms)):\n",
        "                with cols[i % 3]:\n",
        "                    display_name = symptom.replace('_', ' ').title()\n",
        "                    if st.checkbox(display_name, key=f\"pain_{symptom}\"):\n",
        "                        selected_symptoms.append(symptom)\n",
        "\n",
        "    with st.expander(\"Skin Symptoms\"):\n",
        "        if not skin_symptoms:\n",
        "            st.write(\"No matching symptoms found\")\n",
        "        else:\n",
        "            cols = st.columns(3)\n",
        "            for i, symptom in enumerate(sorted(skin_symptoms)):\n",
        "                with cols[i % 3]:\n",
        "                    display_name = symptom.replace('_', ' ').title()\n",
        "                    if st.checkbox(display_name, key=f\"skin_{symptom}\"):\n",
        "                        selected_symptoms.append(symptom)\n",
        "\n",
        "    with st.expander(\"Digestive Symptoms\"):\n",
        "        if not digestive_symptoms:\n",
        "            st.write(\"No matching symptoms found\")\n",
        "        else:\n",
        "            cols = st.columns(3)\n",
        "            for i, symptom in enumerate(sorted(digestive_symptoms)):\n",
        "                with cols[i % 3]:\n",
        "                    display_name = symptom.replace('_', ' ').title()\n",
        "                    if st.checkbox(display_name, key=f\"digestive_{symptom}\"):\n",
        "                        selected_symptoms.append(symptom)\n",
        "\n",
        "    with st.expander(\"Other Symptoms\"):\n",
        "        if not other_symptoms:\n",
        "            st.write(\"No matching symptoms found\")\n",
        "        else:\n",
        "            cols = st.columns(3)\n",
        "            for i, symptom in enumerate(sorted(other_symptoms)):\n",
        "                with cols[i % 3]:\n",
        "                    display_name = symptom.replace('_', ' ').title()\n",
        "                    if st.checkbox(display_name, key=f\"other_{symptom}\"):\n",
        "                        selected_symptoms.append(symptom)\n",
        "\n",
        "    # Display selected symptoms\n",
        "    if selected_symptoms:\n",
        "        st.markdown(\"### Selected Symptoms:\")\n",
        "        cols = st.columns(3)\n",
        "        for i, symptom in enumerate(selected_symptoms):\n",
        "            with cols[i % 3]:\n",
        "                st.markdown(f\"<span class='symptom-tag'>{symptom.replace('_', ' ').title()}</span>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Generate prognosis button\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        generate_btn = st.button(\"Generate Prognosis\", type=\"primary\", use_container_width=True)\n",
        "    with col2:\n",
        "        clear_btn = st.button(\"Clear All\", use_container_width=True)\n",
        "        if clear_btn:\n",
        "            st.rerun()\n",
        "\n",
        "    # Generate prognosis when button is clicked\n",
        "    if generate_btn:\n",
        "        if not selected_symptoms:\n",
        "            st.warning(\"Please select at least one symptom\")\n",
        "        else:\n",
        "            with st.spinner(\"Analyzing symptoms...\"):\n",
        "                # Create input data\n",
        "                input_data = pd.DataFrame(0, index=[0], columns=feature_list)\n",
        "                for symptom in selected_symptoms:\n",
        "                    input_data.loc[0, symptom] = 1\n",
        "\n",
        "                # Apply imputation\n",
        "                input_imputed = imputer.transform(input_data)\n",
        "\n",
        "                # Predict prognosis\n",
        "                proba = model.predict_proba(input_imputed)[0]\n",
        "                top_indices = proba.argsort()[-3:][::-1]  # Get top 3\n",
        "                top_prognoses = label_encoder.inverse_transform(top_indices)\n",
        "                top_confidences = proba[top_indices]\n",
        "\n",
        "                # Log the prediction\n",
        "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                log_entry = {\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"symptoms\": [s.replace('_', ' ').title() for s in selected_symptoms],\n",
        "                    \"prognosis\": top_prognoses[0],\n",
        "                    \"confidence\": float(top_confidences[0]),\n",
        "                    \"alternatives\": [\n",
        "                        {\"prognosis\": p, \"confidence\": float(c)}\n",
        "                        for p, c in zip(top_prognoses[1:], top_confidences[1:])\n",
        "                    ]\n",
        "                }\n",
        "                st.session_state.prognosis_log.insert(0, log_entry)\n",
        "\n",
        "            # Display results\n",
        "            st.markdown(\"<div class='result-box'>\", unsafe_allow_html=True)\n",
        "            st.markdown(f\"### Predicted Prognosis: {top_prognoses[0]}\")\n",
        "            st.markdown(f\"Confidence: {top_confidences[0]:.2%}\")\n",
        "\n",
        "            st.markdown(\"### Alternative Possibilities:\")\n",
        "            for prognosis, confidence in zip(top_prognoses[1:], top_confidences[1:]):\n",
        "                st.write(f\"- {prognosis} ({confidence:.2%})\")\n",
        "\n",
        "            st.markdown(\"<p class='warning'>Note: This is not a medical diagnosis. Please consult a healthcare professional.</p>\", unsafe_allow_html=True)\n",
        "            st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "with tab2:\n",
        "    st.markdown(\"### Prognosis History\")\n",
        "\n",
        "    if not st.session_state.prognosis_log:\n",
        "        st.info(\"No prognosis records yet. Use the Symptom Checker to generate prognoses.\")\n",
        "    else:\n",
        "        for i, entry in enumerate(st.session_state.prognosis_log):\n",
        "            with st.expander(f\"{entry['prognosis']} - {entry['timestamp']}\"):\n",
        "                st.write(f\"*Predicted Prognosis:* {entry['prognosis']} ({entry['confidence']:.2%})\")\n",
        "\n",
        "                st.write(\"*Selected Symptoms:*\")\n",
        "                st.write(\", \".join(entry['symptoms']))\n",
        "\n",
        "                if entry.get('alternatives'):\n",
        "                    st.write(\"*Alternative Possibilities:*\")\n",
        "                    for alt in entry['alternatives']:\n",
        "                        st.write(f\"- {alt['prognosis']} ({alt['confidence']:.2%})\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"MedDoc | Not for actual medical use | Consult healthcare professionals for medical advice\")\n",
        "''')\n",
        "\n",
        "        # Ask user for ngrok auth token\n",
        "        ngrok_token = input(\"\\nPlease enter your ngrok auth token (get one for free at https://ngrok.com): \")\n",
        "        if not ngrok_token.strip():\n",
        "            print(\"No token provided. Using temporary connection which may have limitations.\")\n",
        "        else:\n",
        "            ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "        # Launch Streamlit\n",
        "        print(\"Starting Streamlit app...\")\n",
        "        port = 8501\n",
        "        public_url = ngrok.connect(port)\n",
        "        print(f\"Streamlit app URL: {public_url}\")\n",
        "\n",
        "        # Run Streamlit app\n",
        "        os.system(f\"streamlit run app.py --server.port {port} &\")\n",
        "\n",
        "        # Keep the process alive\n",
        "        print(\"Streamlit app is running. Press Ctrl+C to stop.\")\n",
        "\n",
        "        # Wait for the user to press Ctrl+C\n",
        "        try:\n",
        "            while True:\n",
        "                time.sleep(1)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Stopping Streamlit app...\")\n",
        "            ngrok.kill()"
      ]
    }
  ]
}